{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VIGyIus8Vr7"
   },
   "source": [
    "Take a look at the [repository](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) for more information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wNjDKdQy35h"
   },
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TRm-USlsHgEV",
    "outputId": "452f4b87-91c5-4649-ac5c-c973aa7e5638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CycleGAN-VAE-NST'...\n",
      "remote: Enumerating objects: 2598, done.\u001B[K\n",
      "remote: Counting objects: 100% (83/83), done.\u001B[K\n",
      "remote: Compressing objects: 100% (64/64), done.\u001B[K\n",
      "remote: Total 2598 (delta 42), reused 49 (delta 18), pack-reused 2515 (from 1)\u001B[K\n",
      "Receiving objects: 100% (2598/2598), 8.28 MiB | 17.16 MiB/s, done.\n",
      "Resolving deltas: 100% (1616/1616), done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/')\n",
    "!rm -r /CycleGAN-VAE-NST/\n",
    "!git clone https://github.com/davexhardware/CycleGAN-VAE-NST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Pt3igws3eiVp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/workspace/CycleGAN-VAE-NST/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1EySlOXwwoa",
    "outputId": "43e57a90-fdde-420b-de82-725d61f33352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=1.4.0 in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /venv/main/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.20.1+cu121)\n",
      "Collecting dominate>=2.4.0\n",
      "  Downloading dominate-2.9.1-py2.py3-none-any.whl (29 kB)\n",
      "Collecting visdom>=0.1.8.8\n",
      "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.4/1.4 MB\u001B[0m \u001B[31m13.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m \u001B[36m0:00:01\u001B[0m\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.19.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.8 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m20.8/20.8 MB\u001B[0m \u001B[31m101.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.10-py3-none-any.whl (63 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m63.0/63.0 KB\u001B[0m \u001B[31m11.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /venv/main/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /venv/main/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /venv/main/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /venv/main/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.1.0.106)\n",
      "Requirement already satisfied: networkx in /venv/main/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in /venv/main/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /venv/main/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.17.0)\n",
      "Requirement already satisfied: fsspec in /venv/main/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /venv/main/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /venv/main/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (10.3.2.106)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /venv/main/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (11.4.5.107)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /venv/main/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /venv/main/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.4.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /venv/main/lib/python3.10/site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (11.0.0)\n",
      "Requirement already satisfied: numpy in /venv/main/lib/python3.10/site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (2.1.2)\n",
      "Collecting jsonpatch\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: requests in /venv/main/lib/python3.10/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.32.3)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m37.6/37.6 MB\u001B[0m \u001B[31m64.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "Requirement already satisfied: six in /venv/main/lib/python3.10/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.17.0)\n",
      "Requirement already satisfied: tornado in /venv/main/lib/python3.10/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (6.4.2)\n",
      "Collecting websocket-client\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.8/58.8 KB\u001B[0m \u001B[31m9.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /venv/main/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (6.1.1)\n",
      "Requirement already satisfied: platformdirs in /venv/main/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (4.3.6)\n",
      "Requirement already satisfied: pyyaml in /venv/main/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (6.0.2)\n",
      "Collecting click!=8.0.0,>=7.1\n",
      "  Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m98.2/98.2 KB\u001B[0m \u001B[31m17.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "Collecting sentry-sdk>=2.0.0\n",
      "  Downloading sentry_sdk-2.22.0-py2.py3-none-any.whl (325 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m325.8/325.8 KB\u001B[0m \u001B[31m50.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: setuptools in /venv/main/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (59.6.0)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m207.6/207.6 KB\u001B[0m \u001B[31m36.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "Collecting protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m319.7/319.7 KB\u001B[0m \u001B[31m49.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "Collecting pydantic<3,>=2.6\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m431.7/431.7 KB\u001B[0m \u001B[31m55.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.3.5-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: packaging in /venv/main/lib/python3.10/site-packages (from kagglehub->-r requirements.txt (line 6)) (24.2)\n",
      "Requirement already satisfied: tqdm in /venv/main/lib/python3.10/site-packages (from kagglehub->-r requirements.txt (line 6)) (4.67.1)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.8/62.8 KB\u001B[0m \u001B[31m11.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.27.2\n",
      "  Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m68.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.10/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2025.1.31)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.10/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.10/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /venv/main/lib/python3.10/site-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->-r requirements.txt (line 1)) (2.1.5)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: visdom\n",
      "done wheel for visdom (setup.py) ... \u001B[?25l\n",
      "\u001B[?25h  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408215 sha256=22495445cd5e6c2cb68e9b8baa2f7d913362791d53ca716f3369853ab0adc651\n",
      "  Stored in directory: /root/.cache/pip/wheels/42/29/49/5bed207bac4578e4d2c0c5fc0226bfd33a7e2953ea56356855\n",
      "Successfully built visdom\n",
      "Installing collected packages: websocket-client, smmap, setproctitle, sentry-sdk, scipy, pydantic-core, protobuf, jsonpointer, dominate, docker-pycreds, click, annotated-types, pydantic, kagglehub, jsonpatch, gitdb, visdom, gitpython, wandb\n",
      "Successfully installed annotated-types-0.7.0 click-8.1.8 docker-pycreds-0.4.0 dominate-2.9.1 gitdb-4.0.12 gitpython-3.1.44 jsonpatch-1.33 jsonpointer-3.0.0 kagglehub-0.3.10 protobuf-5.29.3 pydantic-2.10.6 pydantic-core-2.27.2 scipy-1.15.2 sentry-sdk-2.22.0 setproctitle-1.3.5 smmap-5.0.2 visdom-0.2.4 wandb-0.19.7 websocket-client-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8daqlgVhw29P"
   },
   "source": [
    "# Datasets\n",
    "\n",
    "Use your own dataset by creating the appropriate folders and adding in the images.\n",
    "\n",
    "-   Create a dataset folder under `/dataset` for your dataset.\n",
    "-   Create subfolders `testA`, `testB`, `trainA`, and `trainB` under your dataset's folder. For our experiment, we're going to extract the tensors of the images from zip files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rm1cjvqnkd99",
    "outputId": "1d0d1459-d6df-43fe-912f-818bbd95d5a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SNoMfzvqnD-z",
    "outputId": "d152a45e-deb1-4744-d9b9-c9edc439581e",
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-03-05T08:57:00.618593Z",
     "start_time": "2025-03-05T08:57:00.192250Z"
    }
   },
   "source": [
    "!cd /workspace/CycleGAN-VAE-NST\n",
    "!rm -r trainB\n",
    "!rm -r trainA\n",
    "!unzip -d ./ -o ../onepiece_pt.zip\n",
    "!unzip -d ./ -o ../img_align_celeba_pt.zip"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "rm: cannot remove 'trainB': No such file or directory\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "rm: cannot remove 'trainA': No such file or directory\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "unzip:  cannot find or open ./onepiece_pt.zip, ./onepiece_pt.zip.zip or ./onepiece_pt.zip.ZIP.\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "unzip:  cannot find or open ./img_align_celeba_pt.zip, ./img_align_celeba_pt.zip.zip or ./img_align_celeba_pt.zip.ZIP.\r\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CoZmcTXgwHg3",
    "ExecuteTime": {
     "end_time": "2025-03-05T09:04:09.018099Z",
     "start_time": "2025-03-05T09:04:00.654705Z"
    }
   },
   "source": [
    "import os\n",
    "import random\n",
    "def move_train_to_test(train_dir, test_dir, num_files):\n",
    "  if os.path.exists(train_dir):\n",
    "    images = [f for f in os.listdir(train_dir) if os.path.isfile(os.path.join(train_dir, f))]\n",
    "    random.shuffle(images)\n",
    "    images_to_move = images[num_files:]\n",
    "    if not os.path.exists(test_dir):\n",
    "        os.mkdir(test_dir)\n",
    "    for image in [f for f in os.listdir(train_dir) if os.path.isfile(os.path.join(train_dir, f))]:\n",
    "      if image not in images_to_move:\n",
    "          os.rename(os.path.join(train_dir, image), os.path.join(test_dir, image))\n",
    "\n",
    "!cd /workspace/CycleGAN-VAE-NST\n",
    "!rm -r ./datasets/trainA\n",
    "!cp -r ./img_align_celeba_pt/ ./datasets/trainA\n",
    "## COMMENT OUT THIS BLOCK IF YOU WANT TO KEEP ALL IMAGES\n",
    "path='/workspace/CycleGAN-VAE-NST/datasets/trainA'\n",
    "pathdst='/workspace/CycleGAN-VAE-NST/datasets/testA'\n",
    "trainA_size=1000\n",
    "move_train_to_test(path, pathdst, trainA_size)\n",
    "\n",
    "!rm -r ./datasets/trainB\n",
    "!cp -r ./onepiece_pt/ ./datasets/trainB\n",
    "path='/workspace/CycleGAN-VAE-NST/datasets/trainB'\n",
    "pathdst='/workspace/CycleGAN-VAE-NST/datasets/testB'\n",
    "trainB_size=600\n",
    "move_train_to_test(path, pathdst, trainB_size)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "total 168\r\n",
      "drwxr-xr-x 13 vdb vdb  4096 Mar  5 10:04 .\r\n",
      "drwxr-x--- 10 vdb vdb  4096 Mar  5 10:03 ..\r\n",
      "drwxr-xr-x  8 vdb vdb  4096 Mar  5 09:37 .git\r\n",
      "-rw-r--r--  1 vdb vdb   883 Mar  5 09:37 .gitignore\r\n",
      "drwxr-xr-x  3 vdb vdb  4096 Mar  5 10:00 .idea\r\n",
      "drwxr-xr-x  6 vdb vdb  4096 Mar  5 09:54 .venv\r\n",
      "-rw-r--r--  1 vdb vdb 56889 Mar  5 10:04 CycleGAN.ipynb\r\n",
      "-rw-r--r--  1 vdb vdb  3565 Mar  5 09:37 LICENSE\r\n",
      "-rw-r--r--  1 vdb vdb 16461 Mar  5 09:47 README.md\r\n",
      "drwxr-xr-x  3 vdb vdb  4096 Mar  5 09:37 data\r\n",
      "drwxr-xr-x  4 vdb vdb  4096 Mar  5 09:57 datasets\r\n",
      "drwxr-xr-x  2 vdb vdb  4096 Mar  5 09:37 docs\r\n",
      "-rw-r--r--  1 vdb vdb   247 Mar  5 09:37 environment.yml\r\n",
      "drwxr-xr-x  2 vdb vdb  4096 Mar  5 09:37 imgs\r\n",
      "drwxr-xr-x  2 vdb vdb  4096 Mar  5 09:37 models\r\n",
      "drwxr-xr-x  2 vdb vdb  4096 Mar  5 09:37 options\r\n",
      "-rw-r--r--  1 vdb vdb  7122 Mar  5 09:37 pix2pix.ipynb\r\n",
      "-rw-r--r--  1 vdb vdb    79 Mar  5 09:37 requirements.txt\r\n",
      "drwxr-xr-x  2 vdb vdb  4096 Mar  5 09:37 scripts\r\n",
      "-rw-r--r--  1 vdb vdb  4545 Mar  5 09:37 test.py\r\n",
      "-rw-r--r--  1 vdb vdb  4933 Mar  5 09:37 train.py\r\n",
      "drwxr-xr-x  2 vdb vdb  4096 Mar  5 09:37 util\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "rm: cannot remove './datasets/trainA': No such file or directory\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "rm: cannot remove './datasets/trainB': No such file or directory\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T09:04:26.323140Z",
     "start_time": "2025-03-05T09:04:26.087884Z"
    }
   },
   "source": [
    "!ls ./datasets/trainB  | wc -l\n",
    "!ls ./datasets/trainA  | wc -l"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "7603\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "19073\r\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFw1kDQBx3LN"
   },
   "source": [
    "# Training\n",
    "\n",
    "\n",
    "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use  `--batch_size` to change the batch size."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0j5AkG-ny53H",
    "outputId": "c8d86f1d-d971-4fa5-c14d-da4158b265d2",
    "ExecuteTime": {
     "end_time": "2025-03-05T09:34:39.510567Z",
     "start_time": "2025-03-05T09:34:38.326649Z"
    }
   },
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"cuDNN enabled:\", torch.backends.cudnn.enabled)\n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version() if torch.backends.cudnn.is_available() else \"Not available\")\n",
    "print(\"CUDA Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n",
    "\n",
    "x = torch.randn(1, 1, 32, 32, device=\"cuda\")  # Random tensor on GPU\n",
    "conv = torch.nn.Conv2d(1, 1, kernel_size=3).cuda()  # Simple Conv2D layer\n",
    "with torch.backends.cudnn.flags(enabled=True):\n",
    "    output = conv(x)\n",
    "print(\"cuDNN acceleration is working!\" if torch.backends.cudnn.enabled else \"cuDNN is not being used.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "cuDNN enabled: True\n",
      "cuDNN version: 90100\n",
      "CUDA Device Name: NVIDIA GeForce RTX 4070\n",
      "cuDNN acceleration is working!\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0sp7TCT2x9dB",
    "outputId": "ed4aae5c-9d82-47a1-afc8-730ef8610468"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 128                           \t[default: 256]\n",
      "                 dataroot: ./datasets                    \t[default: None]\n",
      "             dataset_mode: tensor                        \t[default: unaligned]\n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: -1                            \t[default: 1]\n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: lsgan                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                 lambda_A: 10.0                          \n",
      "                 lambda_B: 8.0                           \t[default: 10.0]\n",
      "          lambda_identity: 0.0                           \t[default: 0.5]\n",
      "                lambda_kl: 0.5                           \n",
      "               lambda_rec: 0.5                           \n",
      "               latent_dim: 20                            \t[default: 50]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: cycle_gan                     \n",
      "                 n_epochs: 20                            \t[default: 100]\n",
      "           n_epochs_decay: 10                            \t[default: 100]\n",
      "               n_layers_D: 3                             \n",
      "                     name: portraits2op                  \t[default: experiment_name]\n",
      "                      ndf: 32                            \t[default: 64]\n",
      "                     netD: basic                         \n",
      "                     netG: resnet_6blocks                \t[default: resnet_9blocks]\n",
      "                      ngf: 32                            \t[default: 64]\n",
      "               no_dropout: True                          \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \t[default: instance]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 50                            \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                use_wandb: False                         \n",
      "                  verbose: True                          \t[default: False]\n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [TensorDataset] was created\n",
      "The number of training images = 3000\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [CycleGANModel] was created\n",
      "---------- Networks initialized -------------\n",
      "DataParallel(\n",
      "  (module): ResnetGenerator(\n",
      "    (model): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (9): ReLU(inplace=True)\n",
      "      (10): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (11): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (12): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (13): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (14): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (15): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (16): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (17): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (18): ReLU(inplace=True)\n",
      "      (19): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (20): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (21): ReLU(inplace=True)\n",
      "      (22): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (23): Conv2d(32, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (24): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network G_A] Total number of parameters : 1.967 M\n",
      "DataParallel(\n",
      "  (module): ResnetGenerator(\n",
      "    (model): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (9): ReLU(inplace=True)\n",
      "      (10): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (11): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (12): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (13): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (14): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (15): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (16): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (17): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (18): ReLU(inplace=True)\n",
      "      (19): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (20): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (21): ReLU(inplace=True)\n",
      "      (22): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (23): Conv2d(32, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (24): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network G_B] Total number of parameters : 1.967 M\n",
      "DataParallel(\n",
      "  (module): NLayerDiscriminator(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (5): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (8): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (11): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network D_A] Total number of parameters : 0.695 M\n",
      "DataParallel(\n",
      "  (module): NLayerDiscriminator(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (5): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (8): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (11): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network D_B] Total number of parameters : 0.695 M\n",
      "-----------------------------------------------\n",
      "create web directory ./checkpoints/portraits2op/web...\n",
      "/venv/main/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "/root/CycleGAN-VAE-NST/data/tensor_dataset.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  A_pt = load(A_path)\n",
      "/root/CycleGAN-VAE-NST/data/tensor_dataset.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  B_pt = load(B_path)\n",
      "/root/CycleGAN-VAE-NST/data/tensor_dataset.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  A_pt = load(A_path)\n",
      "/root/CycleGAN-VAE-NST/data/tensor_dataset.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  A_pt = load(A_path)\n",
      "/root/CycleGAN-VAE-NST/data/tensor_dataset.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  B_pt = load(B_path)\n",
      "/root/CycleGAN-VAE-NST/data/tensor_dataset.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  A_pt = load(A_path)\n",
      "/root/CycleGAN-VAE-NST/data/tensor_dataset.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  B_pt = load(B_path)\n",
      "/root/CycleGAN-VAE-NST/data/tensor_dataset.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  B_pt = load(B_path)\n",
      "(epoch: 1, iters: 100, time: 0.039, data: 0.301) D_A: 0.304 G_A: 0.433 cycle_A: 4.396 rec_A: 0.000 kl_A: 0.000 idt_A: 0.000 D_B: 0.395 G_B: 0.285 cycle_B: 4.345 rec_B: 0.000 kl_B: 0.000 idt_B: 0.000 \n",
      "(epoch: 1, iters: 200, time: 0.046, data: 0.001) D_A: 0.255 G_A: 0.366 cycle_A: 1.407 rec_A: 0.000 kl_A: 0.000 idt_A: 0.000 D_B: 0.207 G_B: 0.543 cycle_B: 2.707 rec_B: 0.000 kl_B: 0.000 idt_B: 0.000 \n",
      "(epoch: 1, iters: 300, time: 0.042, data: 0.001) D_A: 0.254 G_A: 0.472 cycle_A: 2.236 rec_A: 0.000 kl_A: 0.000 idt_A: 0.000 D_B: 0.165 G_B: 0.450 cycle_B: 2.797 rec_B: 0.000 kl_B: 0.000 idt_B: 0.000 \n",
      "(epoch: 1, iters: 400, time: 0.067, data: 0.001) D_A: 0.295 G_A: 0.419 cycle_A: 2.782 rec_A: 0.000 kl_A: 0.000 idt_A: 0.000 D_B: 0.152 G_B: 0.288 cycle_B: 3.187 rec_B: 0.000 kl_B: 0.000 idt_B: 0.000 \n",
      "(epoch: 1, iters: 500, time: 0.040, data: 0.001) D_A: 0.095 G_A: 0.665 cycle_A: 2.095 rec_A: 0.000 kl_A: 0.000 idt_A: 0.000 D_B: 0.164 G_B: 0.446 cycle_B: 2.832 rec_B: 0.000 kl_B: 0.000 idt_B: 0.000 \n",
      "(epoch: 1, iters: 600, time: 0.042, data: 0.001) D_A: 0.190 G_A: 0.490 cycle_A: 3.498 rec_A: 0.000 kl_A: 0.000 idt_A: 0.000 D_B: 0.169 G_B: 0.632 cycle_B: 1.839 rec_B: 0.000 kl_B: 0.000 idt_B: 0.000 \n",
      "(epoch: 1, iters: 700, time: 0.046, data: 0.001) D_A: 0.123 G_A: 0.343 cycle_A: 3.335 rec_A: 0.000 kl_A: 0.000 idt_A: 0.000 D_B: 0.309 G_B: 0.494 cycle_B: 4.323 rec_B: 0.000 kl_B: 0.000 idt_B: 0.000 \n",
      "(epoch: 1, iters: 800, time: 0.052, data: 0.001) D_A: 0.153 G_A: 0.348 cycle_A: 1.640 rec_A: 0.000 kl_A: 0.000 idt_A: 0.000 D_B: 0.311 G_B: 0.234 cycle_B: 3.270 rec_B: 0.000 kl_B: 0.000 idt_B: 0.000 \n",
      "(epoch: 1, iters: 900, time: 0.045, data: 0.001) D_A: 0.130 G_A: 0.403 cycle_A: 2.173 rec_A: 0.000 kl_A: 0.000 idt_A: 0.000 D_B: 0.137 G_B: 0.659 cycle_B: 2.926 rec_B: 0.000 kl_B: 0.000 idt_B: 0.000 \n",
      "(epoch: 1, iters: 1000, time: 0.044, data: 0.001) D_A: 0.153 G_A: 0.203 cycle_A: 2.379 rec_A: 0.000 kl_A: 0.000 idt_A: 0.000 D_B: 0.147 G_B: 0.808 cycle_B: 2.519 rec_B: 0.000 kl_B: 0.000 idt_B: 0.000 \n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/CycleGAN-VAE-NST/train.py\", line 52, in <module>\n",
      "    model.optimize_parameters()   # calculate loss functions, get gradients, update network weights\n",
      "  File \"/root/CycleGAN-VAE-NST/models/cycle_gan_model.py\", line 209, in optimize_parameters\n",
      "    self.backward_D_A()      # calculate gradients for D_A\n",
      "  File \"/root/CycleGAN-VAE-NST/models/cycle_gan_model.py\", line 147, in backward_D_A\n",
      "    self.loss_D_A = self.backward_D_basic(self.netD_A, self.real_B, fake_B)\n",
      "  File \"/root/CycleGAN-VAE-NST/models/cycle_gan_model.py\", line 141, in backward_D_basic\n",
      "    loss_D.backward()\n",
      "  File \"/venv/main/lib/python3.10/site-packages/torch/_tensor.py\", line 581, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/venv/main/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/venv/main/lib/python3.10/site-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/workspace/CycleGAN-VAE-NST/')\n",
    "    !python train.py --dataroot ./datasets --name portraits2op --lambda_identity 0 --latent_dim 20 --ngf 32 --ndf 32 --norm batch --netG resnet_6blocks --lambda_B 8.0 --dataset_mode tensor --crop_size 128 --batch_size 1 --verbose --n_epochs 20 --n_epochs_decay 10 --display_id -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Once your model has trained, copy over the last checkpoint to a format that the testing model can automatically detect:\n",
    "\n",
    "Use `cp ./checkpoints/<MODELNAME>/latest_net_G_A.pth ./checkpoints/<MODELNAME>/latest_net_G.pth` if you want to transform images from class A to class B and `cp ./checkpoints/horse2zebra/latest_net_G_B.pth ./checkpoints/horse2zebra/latest_net_G.pth` if you want to transform images from class B to class A.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UkcaFZiyASl"
   },
   "source": [
    "# Testing\n",
    "\n",
    "-   `python test.py --dataroot datasets/horse2zebra/testA --name horse2zebra_pretrained --model test --no_dropout`\n",
    "\n",
    "Change the `--dataroot` and `--name` to be consistent with your trained model's configuration.\n",
    "\n",
    "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
    "> The option --model test is used for generating results of CycleGAN only for one side. This option will automatically set --dataset_mode single, which only loads the images from one set. On the contrary, using --model cycle_gan requires loading and generating results in both directions, which is sometimes unnecessary. The results will be saved at ./results/. Use --results_dir {directory_path_to_save_result} to specify the results directory.\n",
    "\n",
    "> For your own experiments, you might want to specify --netG, --norm, --no_dropout to match the generator architecture of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCsKkEq0yGh0"
   },
   "outputs": [],
   "source": [
    "!python test.py --dataroot datasets/horse2zebra/testA --name horse2zebra_pretrained --model test --no_dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzSKIPUByfiN"
   },
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Mgg8raPyizq"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = plt.imread('./checkpoints/<MODELNAME>/web/images/epoch100_fakeA.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0G3oVH9DyqLQ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = plt.imread('./checkpoints/<MODELNAME>/web/images/epoch100_realA.jpg')\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "CycleGAN",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "kernelspec": {
   "display_name": "Python3 (main venv)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
